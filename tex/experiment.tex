\section{Experiments}
\label{sec:expe}

We evaluate the important parameters of \Moca, then we compare it to the other
existing memory analysis tools in terms of performances and trace precision.

\subsection{Methodology}
\label{sec:exp-methodo}

%This section briefly discusses our experimental setup for the evaluation of
%\Moca.

Our main experiments were run on  machines from Grid5000 \texttt{Edel}
cluster~\footnote{A full hardware description is available online:\\
    \url{https://www.grid5000.fr/mediawiki/index.php/Grenoble:Hardware\#Edel}}.
    As some state of the art tools can only run on AMD machines, we also run
    some of the experiment presented in section~\ref{sec:expe-ovh} on
    \texttt{Idfreeze} machine from
    Digitalis~\footnote{\url{http://digitalis.inria.fr/index.php/Idfreeze}}.
    These machines hardware specification is presented in table~\ref{tab:hw}.

\begin{table}[htb]
    \centering
    \begin{tabular}{lp{1.1cm}rrp{1.35cm}p{1.1cm}}
        \toprule
        \multirow{3}{.8cm}{CPU}
        &  & \multicolumn{2}{c}{Vendor} & \multicolumn{2}{c}{Model} \\
        \cmidrule(lr){3-6}
        & \texttt{Edel}  & \multicolumn{2}{c}{Intel} & \multicolumn{2}{c}{Xeon E5520} \\
        & \texttt{Idfreeze} & \multicolumn{2}{c}{AMD} & \multicolumn{2}{c}{Opteron 6174} \\
        \midrule
        \midrule
        \multirow{3}{.8cm}{System totals}
        & & Nodes & Threads & Freq & Memory \\
        \cmidrule(lr){3-6}
        & \texttt{Edel}   & $2$ & $8$ & \SI{2.27}{Ghz} & \SI{24}{Gib} \\
        & \texttt{Idfreeze} & $8$ & $48$ & \SI{2.20}{Ghz} & \SI{256}{Gib}\\
        \midrule
        \midrule
        \multirow{3}{.8cm}{Per node}
        & & Cores & Threads & L3 Cache & Memory \\
        \cmidrule(lr){3-6}
        & \texttt{Edel}   & $4$ & $4$ & \SI{8}{Mib} & \SI{12}{Gib} \\
        & \texttt{Idfreeze} & $6$ & $6$  & \SI{12}{Mib} & \SI{32}{Gib} \\
        \bottomrule
    \end{tabular}
    \caption{Hardware configuration of our evaluation system.}
    \label{tab:hw}
\end{table}

For every experiment, deployed the same \emph{Debian} \emph{Wheezy}
environment running a \texttt{Linux 3.2.41-2} and hyper threading was
disabled.
To make the experiments reproducible, the environment and the trace files are
available
online~\footnote{Experiment traces and environments are available here:\\ \url{http://moais.imag.fr/membres/david.beniamine/experiments.html}}.

We present evaluation results for all the \NPB~\cite{Jin1999}. For
each benchmarks, we compare \Moca with the Pin instrumentation
used in Tabarnac~\cite{Beniamine15TABARNACRR}, one of our previous contribution. This instrumentation traps all the
memory accesses but keeps only tracks of the number of time each thread accesses to
each page, without any other information. Thus it does not require the management
of all the data structures necessary for \Moca.

Each point in each plot is the average of at least $30$ executions. Along with each point,
the error bars represent the standard deviation.
Except for the experiment about the influence of \Moca's parameters, on each
experiment, \Moca was run with it's default parameters: a wakeup interval of
\SI{0.5}{s} for the logging process and \SI{40}{ms} for the monitoring thread.

%\subsection{Experiments}
\subsection{Moca default parameters}
\label{sec:expe-param}

\begin{figure}[htb]
    \centering
    \begin{subfigure}{\linewidth}
        \includegraphics[width=\linewidth]{moca_param.pdf}
        \caption{Execution time.}
        \label{fig:param_time}
    \end{subfigure}

    \begin{subfigure}{\linewidth}
        \includegraphics[width=\linewidth]{moca_param_events.pdf}
        \caption{Number of captured events.}
        \label{fig:param_evts}
    \end{subfigure}
    \caption{Influence of the wakeup intervals on \IS, class A.}
    \label{fig:param}
\end{figure}




Before comparing \Moca to existing tools, we need to evaluate the impact of
the wakeup intervals (logging daemon and monitor thread) on the trace
precision and on the overhead. To do so, we run the \IS benchmark instrumented by \Moca with
a wakeup interval ranging from \SI{0.1}{s} to  \SI{0.9}{s} for the logging daemon and from \SI{20}{ms} to
\SI{100}{ms} for the monitoring thread. For each run, we measure \IS execution time and the number of
accesses captured. We have chosen \IS for this evaluation as it is one of the memory intensive \NPB,
quick experiments with other ones confirmed these results.


We can see on the \fig{fig:param_time} that performances seem too decrease linearly
as the monitoring interval decreases. A closer examination reveals that results
suffer from a high variability under \SI{40}{ms}. 
In addition, the \fig{fig:param_evts} shows
that, at \SI{40}{ms}, \Moca can capture a significant number of events, not significantly improved
\GH{Sur les figures, je vois plutôt 60ms et 50ms repectivement comme intervalles interessants\ldots}
\DB{Les ecarts se sont resserés avec le nombre de runs \ldots}
by lower wakeup intervals. Having chosen this interval of \SI{40}{ms} seconds for the monitoring thread,
we found out that waking up the logging process every \SI{0.4}{s} gave a sufficient reactivity to store
all the collected events.
These two values have been chosen as default values in \Moca.

\subsection{Comparison with existing tools}
\label{sec:expe-ovh}

We evaluate \Moca by comparing it to several state of the art tools: \Mitos
the tracing tool from MemAxes~\cite{Gimenez14Dissecting} which relies on Intel
PEBS technology, the pin instrumentation from
\TABARNAC~\cite{Beniamine15TABARNAC} and MemProf~\cite{Lachaize12MemProf}
which relies on AMD IBS. Every tool is evaluate with its default parameters,
except MemProf which requires\footnote{see
    \url{https://github.com/Memprof/scripts/issues/1}} to increase its
    sampling frequency to work from $0xFFF0$ to $0x8FFF0$ \DB{Fix MemProf,
    higher frequencies}.
We include two version of \Moca in our evaluation: the default version and
\MocaPin which also retrieve the data structure information using a pin
instrumentation.
The \tbl{tab:tools-comp} summarizes the main differences between \Moca and the
other memory profiling tools.

\begin{table}[htb]
    \centering
    \begin{tabular}{p{1.3cm}lC{2.5cm}C{2.5cm}}
        \toprule
        & & Granularity & superset \\
        \cmidrule(lr){3-4}
        \multirow{4}{.8cm}{Trace precision}
        & Tabarnac & Page & Page \\
        & Mitos & Address & None \\
        & MemProf & Address & None \\
        & Moca & Address & Page \\
        \midrule
        & & Time & Sharing and CPU localisation \\
        \cmidrule(lr){3-4}
        \multirow{4}{.8cm}{Other information}
        & Tabarnac & No & Thread sharing\\
        \addlinespace
        & Mitos & Yes & CPU location \\
        \addlinespace
        & MemProf & Yes & Thread sharing and CPU location \\
        \addlinespace
        & Moca & Yes & Thread sharing and CPU location \\
        \midrule
        & & Collection method & Architecture \\
        \cmidrule(lr){3-4}
        & Tabarnac & Instrumentation & Intel, AMD \\
        \addlinespace
        \multirow{4}{.8cm}{Portability}
        & Mitos & Hardware sampling and Instrumentation & Intel, AMD, IBM \\
        \addlinespace
        & MemProf & Hardware sampling & AMD \\
        \addlinespace
        & Moca & Complete sampling + Pin (optional) & Any architecture\\
        \bottomrule
    \end{tabular}
    \caption{Comparison of different memory accesses collection
        tools: Tabarnac~\cite{Beniamine15TABARNACRR},
        Mitos~\cite{Gimenez14Dissecting},
        MemProf~\cite{Lachaize12MemProf} and \Moca}
        \label{tab:tools-comp}
\end{table}

For our evaluation, we compare the different tools on three metrics: first we
compare the slowdown factor of the tool
$slowdown\_factor(tool,bench)=\frac{execution\_time(bench,tool)}{execution\_time(bench)}$
the two last metrics aims at evaluating the precision of the trace, we first
show the number of pages captured during the analysis then the number of
unique addresses. All these experiments have been run on all the \NPB on class A.


\begin{figure}[htb]
    \centering
    \begin{subfigure}{\linewidth}
        \rule{8cm}{7cm}
        %\includegraphics[width=\linewidth]{moca_overhead_nas.pdf}
        \caption{Evaluation on Intel machine}
        \label{fig:ovh-Intel}
    \end{subfigure}

    \begin{subfigure}{\linewidth}
        \rule{8cm}{7cm}
        \caption{Evaluation on AMD machine}
        \label{fig:ovh-AMD}
    \end{subfigure}
    \caption{Slowdown of \Moca on the \NPB compared to state of the art tools.}
    \label{fig:ovh}
\end{figure}

\fig{fig:ovh} shows for each of the \NPB, the slowdown factor when
instrumented by \Moca, \MocaPin and the other existing tools on Intel
(\fig{fig:ovh-Intel}) and AMD (\fig{fig:ovh-AMD}) Machines.

\DB{Rewritte text:\\
    + Benchmarks classification\\
    + Moca vs other tools\\
    + Cost of pin for structure detection}
We can classify these results into three groups of
applications:  for \BT, \DC, \EP, \IS, \LU, \SP and \UA, \Moca is
significantly faster than Tabarnac. This set of benchmarks is interesting as it is made of varied application profiles.
Indeed, if \EP is mostly doing parallel computation with only a few number of
memory accesses, \IS is memory intensive with a random memory access pattern and
\BT, \LU as well as \SP are pseudo applications doing a significant usage of memory.
And while \DC and \UA are categorised as \emph{unstructured computation,
parallel I/O and data movement} by the \NPB website
\footnote{\url{http://www.nas.nasa.gov/publications/npb.html}}, their interaction with memory seems noticeable.
The second group only contains memory oriented benchmarks (\CG and \FT). For this group,
\GH{C'est plutôt équilibré calcul / accès mémoire, non ?}
\DB{Boaf la description CG dit ``irregular memory accesses and communication''
et \FT ``all to all communications}
\Moca is as good as Tabarnac or a bit faster, probably because the balance between computations and memory accesses hides the overhead of the instrumentation.
Finally for \MG, \Moca is
significantly slower than Tabarnac. This benchmark seems to be a pathological
case were the execution time with \Moca has a lot a variability. Actually, in this benchmark, the quantity of pages accessed is huge and exceeds the size
allocated for \Moca data structures. This results in the triggering of \Moca routines that recycle parts of the recent accesses to accept new ones.
We suspect that this is the cause if its bad beahavior.
\DB{Je sais pas vraiment comment présenter les resultats de \MG, c'est mauvais
et variable (sur une centaine de runs ici, la moitié sont très lent et l'autre
moitié plus proche de tabarnac)}
\GH{Et les exec avec plus de mémoire dans le module ?}
\DB{En cours: plus de place dans fpf hashmap + randomization des runs. Au pire
faire au moins courbe en log scale pour plus de lisibilité}
Overall, these experiments show that \Moca is significantly faster than a typical tool based on binary instrumentation
for a majority of benchmarks, and at least as good for most of the others.

\begin{figure}[htb]
    \centering
    \begin{subfigure}{\linewidth}
        \includegraphics[width=\linewidth]{moca_pages_nas.pdf}
        \caption{Number of pages.}
        \label{fig:pages}
    \end{subfigure}
    \begin{subfigure}{\linewidth}
        \includegraphics[width=\linewidth]{moca_addresses_nas.pdf}
        \caption{Number of unique addresses.}
        \label{fig:addr}
    \end{subfigure}
    \caption{Number of pages and unique addresses captured by \Moca and Tabarnac
    on the \NPB.}
    \label{fig:pages-addr}
\end{figure}

Then, we have compared the number of pages and unique addresses captured by \Moca
and Tabarnac during the previous experiment. As expected and as we can see in figure
\fig{fig:pages}, both methods capture the exact same number of
pages, which is the superset of all the memory accesses. Furthermore,
\fig{fig:addr} shows that \Moca also provides a more precise trace than Tabarnac
regarding the number of unique addresses collected. This can be explained by the 
radically different designs of the two tools. While \Moca keeps track of all
the pages accessed during the execution, it also stores, for each triggered page fault, the
exact address of the memory access. On the contrary, to keep the overhead small,
a tool like Tabarnac has to work at a coarser granularity: it only counts the number
of accesses performed by the application for each page address. The result is that Tabarnac
collects space data with the precision of the page (4096 bytes) while \Moca collects them with
the precision of the byte.

\subsection{Summary}
\label{sec:expe-cncl}

We have tested \Moca with various applications and using several parameters.
Our experiments, show that \Moca has a good behavior for a wide range of parameter and
helped us defining their default values. Our experiments also show that, with these
parameters, \Moca is at worst as slow as comparable tools and in most 
cases faster. Moreover, \Moca provides more precise traces than comparable tools.
It is noteworthy that \Moca is the only tool able to provide a detailed trace with temporal,
spacial and sharing information while providing guarantees on the information
% \GH{Tu ne parles vraiment de sharing qu'ici !!}
% \DB{Dans la Table I de design aussi, j'ai modifié un paragraphe pour insister
% dessus}
lost during the sampling.
