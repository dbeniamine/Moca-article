\section{Experiments}
\label{sec:expe}

We first evaluate the important parameters of \Moca, then we compare it to the other
existing memory analysis tools in terms of  trace precision and performances.

\subsection{Methodology}
\label{sec:exp-methodo}

%This section briefly discusses our experimental setup for the evaluation of
%\Moca.

Our main experiments were run on  machines from Grid5000 \Edel
cluster.
    As some state of the art tools can only run on AMD machines, we also run
    some of the experiment presented in section~\ref{sec:expe-ovh} on
    \Idfreeze machine from
    Digitalis.
    These machines hardware specification is summarized in
    \tbl{tab:hw}\footnote{Both platforms provides an online hardware description:\\
        \url{https://www.grid5000.fr/mediawiki/index.php/Grenoble:Hardware\#Edel}
     \\\url{http://digitalis.inria.fr/index.php/Idfreeze}}.

\begin{table}[htb]
    \centering
    \begin{tabular}{lp{1.1cm}rrp{1.35cm}p{1.1cm}}
        \toprule
        \multirow{3}{.8cm}{CPU}
        &  & \multicolumn{2}{c}{Vendor} & \multicolumn{2}{c}{Model} \\
        \cmidrule(lr){3-6}
        & \Edel  & \multicolumn{2}{c}{Intel} & \multicolumn{2}{c}{Xeon E5520} \\
        & \Idfreeze & \multicolumn{2}{c}{AMD} & \multicolumn{2}{c}{Opteron 6174} \\
        \midrule
        \multirow{3}{.8cm}{System totals}
        & & Nodes & Threads & Freq & Memory \\
        \cmidrule(lr){3-6}
        & \Edel   & $2$ & $8$ & \SI{2.27}{Ghz} & \SI{24}{Gib} \\
        & \Idfreeze & $8$ & $48$ & \SI{2.20}{Ghz} & \SI{256}{Gib}\\
        \midrule
        \multirow{3}{.8cm}{Per node}
        & & Cores & Threads & L3 Cache & Memory \\
        \cmidrule(lr){3-6}
        & \Edel   & $4$ & $4$ & \SI{8}{Mib} & \SI{12}{Gib} \\
        & \Idfreeze & $6$ & $6$  & \SI{12}{Mib} & \SI{32}{Gib} \\
        \bottomrule
    \end{tabular}
    \caption{Hardware configuration of our evaluation system.}
    \label{tab:hw}
\end{table}

For every experiment, we deployed the same \emph{Debian} \emph{Jessie}
environment running a \texttt{Linux 3.16.0-4} with hyper threading was
disabled.
To keep our research reproducible, every file needed for the experiments and
generated by our experiments is available online\footnote{\url{http://moais.imag.fr/membres/david.beniamine/experiments.html}}. It is possible to download
only the filtered trace (csv files) and analysis scripts (R-markdown) or to
also retrieve the raw traces and the script used to filter them. Instructions
are also given to reproduce these experiments.

\begin{table}[htb]
    \centering
    \begin{tabular}{p{1.3cm}lcc}
        \toprule
        & & Mechanisms* & Architecture \\
        \cmidrule(lr){3-4}
        \multirow{4}{.8cm}{Portability}
        & \TABARNAC & Inst & Intel, AMD \\
        \addlinespace
        & \Mitos & PEBS + Inst & Intel \\
        \addlinespace
        & \MemProf & IBS & AMD \\
        \addlinespace
        & \Moca & PfI (+ Inst) & Any\\
        \midrule
        & & Granularity & superset \\
        \cmidrule(lr){3-4}
        \multirow{4}{.8cm}{Trace precision}
        & \TABARNAC & Page & Page \\
        & \Mitos & Address & None \\
        & \MemProf & Address & None \\
        & \Moca & Address & Page \\
        \midrule
        & & \multicolumn{2}{C{5cm}}{Time, Thread sharing, CPU**} \\
        \cmidrule(lr){3-4}
        \multirow{4}{.8cm}{Additional information}
        & \TABARNAC & \multicolumn{2}{C{5cm}}{Thread sharing} \\
        \addlinespace
        & \Mitos & \multicolumn{2}{C{5cm}}{Time + CPU} \\
        \addlinespace
        & \MemProf & \multicolumn{2}{C{5cm}}{All}  \\
        \addlinespace
        & \Moca & \multicolumn{2}{C{5cm}}{All} \\
        \bottomrule
    \end{tabular}
    \caption{Comparison of different memory accesses collection
        tools.
        %\TABARNAC~\cite{Beniamine15TABARNACRR},
        %\Mitos~\cite{Gimenez14Dissecting},
        %\MemProf~\cite{Lachaize12MemProf} and \Moca.
        \\
        \emph{*~Inst: Binary instrumentation, PfI: Pagefault Interception}\\
        \emph{**~CPU on which the access occured}}
        \label{tab:tools-comp}
\end{table}

We evaluate \Moca by comparing it to several state of the art tools: \Mitos
the tracing tool from MemAxes~\cite{Gimenez14Dissecting} which relies on Intel
PEBS technology. 
\TABARNAC~\cite{Beniamine15TABARNACRR}, one of our previous contribution,
based on a Pin instrumentation which traps all the memory accesses but keeps
only tracks of the number of time each thread accesses to each page, without
any other information. Thus it does not require the management of all the data
structures necessary for \Moca.
\MemProf~\cite{Lachaize12MemProf} which is designed to analyze NUMA
performance issues and relies on AMD IBS.
\tbl{tab:tools-comp} summarizes the main differences
between \Moca and the other memory profiling tools. All the tools are
evaluated on each of the 10 \NPB~\cite{Jin1999}.

Each point in each plot is the average of at least $30$ executions. Along with each point,
the error bars represent the standard deviation.
Except for the experiment about the influence of \Moca's parameters, on each
experiment, \Moca was run with it's default parameters: a wakeup interval of
\SI{0.5}{s} for the logging process and \SI{50}{ms} for the monitoring thread.

%\subsection{Experiments}
\subsection{Moca default parameters}
\label{sec:expe-param}

Before comparing \Moca to existing tools, we need to evaluate the impact of
the wakeup intervals (logging daemon and monitor thread) on the trace
precision and on the overhead. To do so, we run the \IS benchmark instrumented by \Moca with
a wakeup interval ranging from \SI{0.1}{s} to  \SI{0.9}{s} for the logging daemon and from \SI{20}{ms} to
\SI{100}{ms} for the monitoring thread. For each run, we measure \IS execution time and the number of
accesses captured. We have chosen \IS for this evaluation as it is one of the memory intensive \NPB,
quick experiments with other ones confirmed these results. This experiment was
run on a machine from the \Edel cluster.

\begin{figure}[htb]
    \centering
    \begin{subfigure}{\linewidth}
        \includegraphics[width=\linewidth]{moca_param.pdf}
        \caption{Execution time.}
        \label{fig:param_time}
    \end{subfigure}
    \begin{subfigure}{\linewidth}
        \includegraphics[width=\linewidth]{moca_param_events.pdf}
        \caption{Number of captured events.}
        \label{fig:param_evts}
    \end{subfigure}
    \caption{Influence of the wakeup intervals on \IS, class A.}
    \label{fig:param}
\end{figure}

We can see on the \fig{fig:param_time} that performances decrease when we
reduce the monitoring wakeup interval, at \SI{40}{ms}
performances seems to reach the worst level. In addition, the
\fig{fig:param_evts} shows that at \SI{50}{ms} we can still obtain more than
\SI{50000}{events} which seems quite reasonable. Finally for this value, a logging
interval of \SI{0.5}{s} seems to provide a good trade-off  between
performances and precision.
These two values have been chosen as default values in \Moca.



\subsection{Comparison with existing tools}
\label{sec:expe-ovh}

As preliminary experiments shows that \Mitos capture by
default way less events than \TABARNAC and \Moca, we also compare our tool to
\Mitos with a sampling period chosen to increase the number of pages
captured, We call this version \MitosTun.

Due to technical limitations \MemProf default sampling period have been
increased from  $0x8FFF0$ to $0x1FFFF0$ and the library used for retrieving
data structure information was disabled.
%\footnote{see \url{https://github.com/Memprof/scripts/issues/1}}

Finally our evaluation also differentiate \Moca (kernel module only) from
\MocaPin which also retrieve the data structure information using a pin
instrumentation, we do this differentiation to evaluate the impact of Pin on
\Moca performances.

We compare the different tools on two aspect: trace
precision and induced slowdown. The first experiment shows the number of pages
and unique addresses captured during the analysis. The second one compare the
slowdown factor of the different tools.
%$slowdown\_factor(tool,bench)=\frac{exec\_time(bench,tool)}{exec\_time(bench)}$.
All these experiments have been run on each of the \NPB on class A.

\begin{figure}[htb]
    \centering
    \begin{subfigure}{\linewidth}
        \includegraphics[width=\linewidth]{moca_pages_intel.pdf}
        \caption{Number of pages.}
        \label{fig:pages}
    \end{subfigure}
    \begin{subfigure}{\linewidth}
        \includegraphics[width=\linewidth]{moca_addr_intel.pdf}
        \caption{Number of unique addresses.}
        \label{fig:addr}
    \end{subfigure}
    \caption{Number of pages and unique addresses captured by \Moca and other
        state of the art tools
    on the \NPB. Y-axis is in log scale.}
    \label{fig:pages-addr}
\end{figure}

\fig{fig:pages-addr} presents the results of the precision evaluation of the
different tools. The values used for \Mitos, \MitosTun, \Moca, \MocaPin and
\TABARNAC comes from runs on \Edel machines, while \MemProf results comes from
\Idfreeze.
\DB{Biais + de thread sur \Idfreeze ?}

We can see on \fig{fig:pages} that \Moca and \TABARNAC capture the exact same
number of pages. As explained earlier these tools are the only one that
guarantee to capture a superset of the accessed pages. Thus this is the total
number of pages used during the execution. Furthermore, we can notice that
\MocaPin captures slightly more pages which correspond to Pin data. Still
this difference is small compared to the total number of captured pages
therefore the noise induced in the trace should be negligible.

\Mitos often provides one order less pages than \Moca and \TABARNAC, while
tunning \Mitos sampling period can help improve this number it still miss a
considerable number of pages.

From \fig{fig:addr}Â we can see that, as expect, the number of unique address captured by
\TABARNAC is exactly the number of pages, this is due to the fact that
\TABARNAC works at the page granularity. For almost half the benchmarks (\BT,
\EP, \LU, \SP and \UA) \MitosTun provides a number of unique addresses
comparable to \Moca while \Mitos without tunning is always under these values.
This means that if \Mitos miss a considerable part of the address-space, it
provide a fair sampling on the captured pages.

\DB{missing MemProf result}

These results proves that most existing tools can miss a considerable part of
the address-space while \Moca guarantee to provide a superset of the accessed
pages. Furthermore they show that \Moca is the only existing tool able to provide a
trace precise enough to have an overview an application's memory behavior. As
stated, not only our tool provide a complete trace at the granularity of the
page but it is also more precise than the other existing tools in term of
number of unique addresses captured. Finally, adding a Pin instrumentation to
\Moca does not seems to disturb considerably the trace quality thus it seems
safe to use it.

\begin{figure}[htb]
    \centering
    \begin{subfigure}{\linewidth}
        \includegraphics[width=\linewidth]{moca_overhead_intel.pdf}
        \caption{Evaluation on \Edel (Intel)}
        \label{fig:ovh-Intel}
    \end{subfigure}
    \begin{subfigure}{\linewidth}
        \rule{8cm}{6cm}
        \caption{Evaluation on \Idfreeze (AMD)}
        \label{fig:ovh-AMD}
    \end{subfigure}
    \caption{Slowdown factor of \Moca on the \NPB compared to state of the art tools.
    Y-axis is in log scale.}
    \label{fig:ovh}
\end{figure}

\fig{fig:ovh} shows for each of the \NPB, the slowdown factor when
instrumented by \Moca, \MocaPin and the other existing tools on Intel
(\fig{fig:ovh-Intel}) and AMD (\fig{fig:ovh-AMD}) Machines the Y-axis is in
log scale.

From \fig{fig:ovh-Intel}, we can see that \Mitos and \MitosTun overhead is
almost negligible which is not the case for \Moca and \TABARNAC, this
difference is explained by the results of the previous experiment, as \Mitos
only collect a few addresses even with some fine tuning, it's overhead is
necessary low.

We can classify the benchmarks into three groups:
for \BT, \CG, \EP, \LU, \SP and \UA, \Moca is
significantly faster than \TABARNAC. This set of benchmarks is interesting as it is made of varied application profiles.
Indeed, if \EP is mostly doing parallel computation with only a few number of
memory accesses, \CG is memory intensive and
\BT, \LU as well as \SP are pseudo applications doing a significant usage of memory.
And while \UA is categorised as \emph{unstructured computation,
parallel I/O and data movement} by the \NPB
website\footnote{\url{http://www.nas.nasa.gov/publications/npb.html}}, its
interactions with memory seems noticeable.

The second group only contains memory oriented benchmarks (\DC and \FT and
\IS). For this group, \Moca is as good as \TABARNAC or a bit faster, probably
because the balance between computations and memory accesses hides the
overhead of the instrumentation.

For the last benchmark: \MG, \Moca is significantly slower than \TABARNAC. This benchmark
seems to be a pathological case were the execution time with \Moca has a lot a
variability. By looking at our experiment logs, we found that \MG seems to
generate a lot of conflicts on \Moca false page fault hash map. A solution
could be to increase the size of this hash map which is quite difficult as
memory space in the kernel is limited, another solution would consist on
working on a smaller version of \MG and see if the analysis is still useful.


Finally, by comparing \Moca to \MocaPin, we can see that when \Moca slowdown
factor is low, using Pin does not have a considerable impact on it but when
\Moca's overhead start to be high, using Pin actually improve the
performances. While this can seems abnormal it has a very simple explanation:
as Pin instrumentation function are not memory intensive, every time Pin
interfere with the normal execution, it gives enough time to \Moca to flush
its buffers, thus it reduce the number of conflict in \Moca different
hashmaps.

\subsection{Summary}
\label{sec:expe-cncl}

We have tested \Moca with various applications and using several parameters.
Our experiments, show that \Moca has a good behavior for a wide range of
parameter and helped us defining their default values. Our experiments also
show that, with these parameters, provides significantly more precise traces
than state of the art tools. Compared to the tools that provide comparable
(but still less precise traces) \Moca is at worst as slow as these tools and
often faster.  It is noteworthy that \Moca is the only tool able to provide a
detailed trace with temporal, spacial and sharing information while providing
guarantees on the information lost during the sampling.
