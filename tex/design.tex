\section{Design}
\label{sec:design}

\Moca consist of a Linux kernel module that can be loaded at runtime,  a script
in charge of both loading this module with the proper parameters and launching the
monitored application on the user behalf
and an optional Pintool (c++ library based on Intel Pin) to retrieve data
structure informations.
It neither relies on architecture specific
technologies such as AMD IBS or Intel PEBS, nor on architecture dependent kernel
code, kernel patch or kernel modifications.
Therefore it is highly portable and can be run on any recent Linux kernel
from the $3.0$.

\Moca collects \emph{complete} traces in the sense that the exact set
of pages accessed by the application is deduced from the collected events
at all times during the execution. Thus, it is \emph{complete} at the page granularity.
Other information such as exact addresses and access times are a sample of
the set of all the accesses.

Two tasks are addressed by the kernel module included in \Moca. The first one is
keeping track of the set of pages accessed by the application during an elementary monitoring
interval. The second one is managing somehow the huge quantity of data produced
by the trace collection within the kernel space in-between regular flushes toward
the user space. Of course, these two tasks should be as slightly intrusive as possible.

To make the trace more readable, \Moca can also retrieve data structure
names, addresses and size using a Pin~\cite{Luk05Pin}
instrumentation. When enabled \Moca runs the application twice with \texttt{virtual
address space randomization} disabled. The first time the application runs only
under Pin instrumentation and the second time \Moca module is loaded but the
instrumentation is disabled. This instrumentation reads static data
structures information in each executed binary file and stores data about structures larger than
one page. It also intercepts all calls to \texttt{malloc} family functions
and names malloced structures according to their call path.
\Moca and Pin are run separately because preliminary experiments showed us that combining both
tools resulted in a degradation of the trace quality. Our instrumentation remains lightweight, the
added cost of the Pin instrumentation is the cost of a regular execution 
added to a small constant overhead for each binary opened and each allocation performed.
%initialization. Thus the overhead of using \Moca and the Pin instrumentation
%is basically \Moca overhead plus one time the normal execution time.

\subsection{Collecting memory accesses}

In recent Linux kernel, physical memory pages are lazily allocated to page frames during
the execution. The first access to a page in the virtual address space triggers a page fault.
To handle this page fault, Linux allocates a physical page to the requested page frame.
Such a page fault can also be triggered when a thread access a shared page modified by
another thread. \Moca is built upon the possibility to monitor memory accesses by registering
a callback on Linux page faults.

Nevertheless, a page fault does not occur at each memory access. To monitor memory accesses during
the course of the execution, we need to reenable a page fault similar to the first access, but
performed on a regular basis and on behalf of \Moca.
In other words, we need to generate false page fault by periodically marking as \emph{not present}
the pages accesses by the application.
In Linux terminology, this means that any access to the page will trigger a page fault which
will have to be handled, in this case, by a handler contained in \Moca.

This method has several advantages over hardware sampling or
instrumentation. First it provides a superset of all the memory accesses, because it
guarantee that each page accessed by the monitored application will at least fault once
and will be traced. Thus, at the end of each monitoring interval, we know the exact set
of accessed pages from which we deduce a superset of actual memory accesses.
This comes in addition to the fact that each false page fault generated provides \Moca with
exact information about one memory access. This means that \Moca also performs a sampling
of all the memory accesses. Because it is designed to manage large chunks of trace data
within the kernel space, it also stores all the details about these samples in the collected trace.

\Moca differs from instruction sampling because it is not necessary to increase the monitoring
frequency of \Moca to collect a \emph{complete} trace. On the contrary, when using instruction sampling,
if the pages of the application are accessed in an unbalanced manner, it is necessary to increase
the sampling frequency to get a precise picture of the memory working set of the application.
Nevertheless, there can be no guarantee that a chosen sampling frequency will result in a trace
that contains all the pages on which the application works.

\Moca also differs from instrumentation based tools because, just as in the case of sampling,
memory accesses that are not collected in the trace are not trapped at all by a false page fault. Furthermore, the
remaining memory accesses, those which are collected, are trapped using a hardware mechanism and
Linux kernel probes. Both are lightweight mechanisms, this means that
the overall instrumentation overhead of \Moca is likely to be much lower.
Indeed, instrumentation based methods often work at a high granularity, collecting few information,
in order to restrain their naturally high overhead.

%In short, \Moca collects complete traces at the granularity of the page, whereas instruction
%sampling cannot guarantee any completeness of the collected trace. And \Moca is 
%more efficient than binary instrumentation (such as Pin) as it relies on hardware mechanisms
%to intercept page faults and does not have to trap all the memory instructions.
%Furthermore \Moca traces provides information on time, thread sharing and CPU
%location of each captured accesses.

%Intercepting page faults instead of doing hardware sampling, guaranty that
%every page of the analyzed application will be intercepted. Therefore \Moca
%provide a \emph{complete} trace at the granularity of the page. Such guaranty
%is not provided by any other tool based on sampling. Instrumentations based
%tools that traces every memory accesses provides this guaranty but to keep
%their overhead reasonable they have to drop a part of the information.
%Furthermore while \Moca traces are \emph{complete} at the page granularity,
%they contains every intercepted addresses, thus they provide detailed
%information at the byte granularity.

\subsection{Managing data}
\label{sec:design-tech}

In this section we present in details how the main components of \Moca
interact and how \Moca addresses the management of data it collects
within the kernel space.
During the execution, \Moca needs to store three kinds of information:
\begin{enumerate}
    \item The set of \emph{tasks} (Linux internal representation of threads and processes) which are
monitored. This is necessary because page faults will also be triggered by other tasks which do not belong to
the monitored application.
    \item The set of all page faults which have been injected by \Moca,
        required to distinguish false page faults from regular ones, because their handling differs.
    \item The set of addresses recently accessed by each task, this set
        correspond to the actual memory trace. It is required to keep it in
        kernel space as we need to reinject these false page faults at the end of each monitoring interval. Afterwards,
        this set is transfered to the user space by a dedicated process and appended to the resulting trace.
\end{enumerate}

The first two types of information are stored in preallocated hashmaps in order to reduce the
runtime overhead of their management.  These hashmaps are read at each page fault but rarely
written, only when a new task of the monitored application triggers its first page
fault or when \Moca creates some false page faults. We can protect
them with Linux kernel built-in \emph{rwlocks}.
% La question ne se pose plus, la phrase a été retournée depuis, à l'époque elle parlait de priorité entre lecteurs et rédacteurs
%\GH{Un peu contradictoire si on sait que les rwlocks favorisent les lecteurs\ldots}
The third type of information is the actual
trace, divided, for each task, in a private set of \emph{chunks}. A chunk is the set of
accesses that have been collected during the monitoring time interval. Chunks provide a discretization
of the time, each chunk embed two timestamp to delimit its temporal bounds.
The accesses are not timestamped but their order in the trace file is their
order of arrival in the chunk.
The advantage is that it reduces the volume of information stored for the accesses.

\begin{figure}[htb]
    \centering
    \resizebox{.9\linewidth}{!}{
        \Input{moca-tikz.tex}
    }
    \caption{Interactions betweens \Moca's main component and Linux}
    \label{fig:moca}
\end{figure}

This discretization of the time, materialized as a sequence of chunks, is useful as it let the
different components of \Moca work concurrently on different chunks.  Indeed the traced
program will always work on \emph{current} chunks, one for each core, while the logging daemon,
which flushes the trace from memory to permanent storage works on \emph{completed} chunks. A
monitoring kernel thread, manages the progress of this logical time. It periodically wakes up, marks the current chunks as
\emph{ending} and invalidates all the pages they reference. Once all pages of the \emph{ending}
chunks have been invalidated, it marks these chunks as \emph{completed}. Finally, the
logging process flushes \emph{completed} chunks to the filesystem at a lower
rate, in order to reduce the overhead of I/Os requests,
\GH{Pourquoi à un rythme moins élevé ??? En théorie des files d'attentes ce genre de choses = débordement...}
\DB{L'idée était de limiter la bande passante disque, et croiser les doigt
pour que les files soient assez grosses \ldots Il faudrait essayer un logging
interval très petit sur MG.}
\GH{On peut aussi éventuellement rajouter les trois mots précédents, histoire de dire que le but
est de factoriser les requêtes, pas de remplir la mémoire}
and recycle them as empty places for upcoming chunks.  \fig{moca} depicts the interaction between the
different processes and threads of \Moca, its data structures and Linux.

%Eventually, \Moca generates one csv file, each line of this file
%describe one access giving its physical and virtual address, the number of
%read and writes captured, a bitmask indicating on which CPU the access
%occurred, the start and end timestamp of its chunk and the
%internal identifier of the task which triggered it. A set of access sharing the same
%timestamps and task identifier correspond to a chunk. The order of accesses inside a
%chunk is preserved.

%\begin{algorithm}[htb]
%    \caption{Monitoring thread algorithm}
%    \label{algo:monTh}
%    \begin{algorithmic}[1]
%        \While{\Callp{NotFinished}{}}
%            \ForAll{t in \Callp{MonitoredTasks}{}}
%                \State \Callp{EndCurrentChunk}{t}
%                    \ForAll{Addr in \Callp{PreviousChunk}{t}}
%                        \State \Callp{WriteLockPF}{}
%                        \State \Callp{AddFalsePF}{Addr}
%                        \State \Callp{WriteUnlockPF}{}
%                    \EndFor
%                \State \Callp{MarkPreviousChunkFinished}{t}
%            \EndFor
%            \State \Callp{sleep}{MonitorThreadWakeUpInterval}
%        \EndWhile
%    \end{algorithmic}
%\end{algorithm}

%The monitoring thread is a kernel thread %that uses the algorithm~\ref{algo:monTh}, is
%in charge of enabling false page faults destined for \Moca. It performs its task by
%removing the \texttt{PRESENT} flags from the \texttt{Page Table Entry}
%(\texttt{PTE}) that corresponds to each recently
%accessed addresses. Of course, the 
%shorter is the period between two wakeups, the more
%precise the trace is.
%This period is called \emph{monitor thread wakeup interval} (or \emph{monitor
%interval}).
%But invalidating all the recently accessed pages takes time as it requires
%to take a write lock on the page faults hashmap. This write lock
%delays any pending false page fault in the monitored application. Thus the wakeup frequency of the
%monitoring thread cannot be too high, otherwise its action becomes too intrusive.
%The \texttt{MonitorThreadWakeUpInterval} \Moca parameter lets the user change the default setting
%that we have empirically chosen after a few experiments.

%\begin{algorithm}[htb]
%    \caption{Logging daemon algorithm. Note that no locks are required to
%    work on completed chunks.}
%    \label{algo:flushTh}
%    \begin{algorithmic}[1]
%        \While{\Callp{NotFinished}{}}
%        \ForAll{t in \Callp{MonitoredTasks}{}}
%                \ForAll{c in \Callp{FinishedChunks}{t}}
%                \State \Callp{WriteTraceToDisk}{c}
%                \State \Callp{ReinitChunk}{c}
%                \EndFor
%            \EndFor
%            \State \Callp{sleep}{LoggingDaemonWakeupInterval}
%        \EndWhile
%    \end{algorithmic}
%\end{algorithm}

%The logging daemon %that uses algorithm~\ref{algo:flushTh},
%is a userspace process
%which periodically reads \texttt{/proc} pseudo files used by \Moca kernel module to export
%its data to userspace. Those reads trigger a
%callback method in our tool which flush completed chunks from memory to
%disc. As it works on completed chunks, it does not directly interfere with the
%normal application execution. Especially, no lock is required to access to these completed chunks,
%and, as it mostly generates disc I/O, it does not compete much for CPU.
%\Moca has just to wake him up sufficiently often so that the kernel module does not run out
%of free space to store upcoming chunks.

%\begin{algorithm}[htb]
%    \caption{Page fault handler}
%    \label{algo:PageFault}
%    \begin{algorithmic}[1]
%        \Function{HandleFault}{task t,void *addr, int type}
%            \If {\Callp{IsNotMonitoredTask}{t}}
%                \If {!\Callp{AddToMonitoredIfNeeded}{t}}
%                    \State \Return \Comment{Resume page fault}
%                \EndIf
%            \EndIf
%            \State \Callp{AddToChunk}{t,addr, type}
%            \Comment{Trace the access}
%            \State \Callp{ReadLockPF}{}
%            \State \Callp{TryFixFalsePageFault}{addr}
%            \State \Callp{ReadUnlockPF}{}
%            \State \Callp{UpdateClock}{}
%            \State \Comment{Resume page fault. If a fix occurred, Linux will
%                silently abort the page fault}
%        \EndFunction
%    \end{algorithmic}
%\end{algorithm}

Each time a page fault occurs, it is trapped by the handler registered by \Moca.
%algorithm~\ref{algo:PageFault}.
This handler first finds out if the task
(thread or process) responsible for the page fault is
monitored or not. If not, it has to check if the task is a child of a monitored
task and, in this case, it starts monitoring it. We only need a read lock
to access to the hashmap containing the monitored tasks in order to answer to these
two questions.
If and only if the second answer is yes, it is necessary to take
a write lock to add the task to the monitored ones.
This case occurs only at the first page fault of a new monitored
process or thread which is quite rare and usually occurs only at the
initialization time. For instance, in the benchmarks used for
the evaluation it happens $8$ times for $5\times10^6$ accesses.
At the end of this phase, if the task is still not monitored, we let Linux handle the page fault as usual.

When a monitored task triggers a page fault, the access is first added
to its current chunk. For each access, \Moca stores the exact address, it's type (read
or write) and the CPU on which the fault occurred.  Then, it checks if the page
fault has been injected by \Moca or if this is a legitimate page fault.

In the first
case, \Moca \emph{fixes} it by setting the \texttt{PRESENT} flag on the
\texttt{Page Table Entry}.
The hashmap entry indicating that the fault was triggered by \Moca should then
be removed, but this would required a write lock, so we only mark the hashmap
entry as \texttt{BAD}. \texttt{BAD} entries are removed, if needed, when the
monitoring thread injects false page faults as this injection already requires to hold the
write lock.

If a fix occurred in the \Moca handler, Linux silently aborts the page fault
when it resumes its execution. In the other case, it executes a normal page fault handling. Each page
fault increases an atomic clock that is used to timestamp the beginning and end
of the chunks.
%In this description, one can notice that a race might occur if the monitoring thread enables a false page fault between the
%end of our handler and the end of Linux page fault handler. To avoid that, \Moca stores
%for each CPU the last address that faulted, and does not clear it.

All default values for the parameters that can influence either the accuracy of the trace or the
overhead of the tool (such as the number and size of chunks, wakeup intervals
for the monitoring thread and the logging process \ldots) can be overridden by the
user. Nevertheless, reasonable defaults have been defined from the experimental study
detailed in section~\ref{sec:expe-param}.
