%!TEX encoding=UTF-8 Unicode
%!TEX root=../tabarnac.tex

\DB{Add ref review1 HPDC ?\\
    http://dl.acm.org/citation.cfm?id=2287114\\
    http://dl.acm.org/citation.cfm?id=1168861\\
    https://www.usenix.org/legacy/event/usenix06/tech/full\_papers/jones/jonesi\_html/}
\section{Related Works}
\label{sec:related}

Several generic tools have been designed to analyze and improve parallel
applications performances, such as Intel's VTune~\cite{Reinders05VTune},
Performance Counter Monitor~(PCM)~\cite{Intel2012b}, the
HPCToolkit~\cite{Adhianto10HPCTOOLKIT}, and AMD's
CodeAnalyst~\cite{Drongowski2008}. All of these tools use performance
counters and execution traces to show when and where CPUs are idle, and thus
highlight potential places for improvements.
But they mostly focus on CPU related information and provide only
indirect data about memory performances, that can be computed from the performance counters values.

As performances counters are architecture dependent and are not always easily
understandable, higher level libraries such as \emph{PAPI}~\cite{Weaver13PAPI} and
\emph{Likwid}~\cite{Treibig10LIKWID} have been developed to ease such analysis. These
libraries are able to derive more abstract and understandable metrics from raw hardware counters.
For instance Likwid provides several groups of metrics related to memory
allowing the user to compute bandwidth of each cache level and between a CPU
and the main memory.
Overall, a lot of studies provide a memory analysis solely based
on information collected through hardware performance counters~\cite{Majo13(Mis)understanding,
Jiang14Understanding,Bosch00Rivet,Weyers14Visualization,Tao01Visualizing,DeRose01Hardware}.
Despite providing a good global summary about memory performance figures, these counters only provide a partial view of the execution. They
account for memory related events from the point of view of one processor, but
do not give precise insight about the place and the cause of these events.

Another approach used by several
tools~\cite{Lachaize12MemProf,McCurdy10Memphis,Liu14Tool,Gimenez14Dissecting}
consists in using sampling mechanisms such as AMD's Instruction Based Sampling
(IBS)~\cite{Drongowski07Instructionbased} or Intel Precise Event Based
Sampling (PEBS)~\cite{Levinthal2009} to trace the applications execution. These methods
provide \emph{incomplete} sampling: some parts of the memory can be accessed without
being noticed by the tool if none of the associated instructions are part of the sampled
instructions.
Thus they can ignore some parts of the memory less frequently accessed but in which
optimization could take place.
Furthermore while these sampling mechanisms can only monitor a small set of event
at the time due to hardware limitations (number of available processor
registers), there is an important number of existing events to reflect the
complexity of memory hierarchy which make hard to trace every memory
access with only one analysis.
One way to lessen the impact of these limitations is to run several times the
instrumentation and use advanced methods such as
folding~\cite{Servat15Towards} to generate a more accurate summary trace.
Nevertheless, this make the instrumentation cost grow accordingly.
Moreover writing (and sometimes) using tools that relies on hardware mechanisms
requires a deep knowledge of the processor. And as processor evolves,
such tools are hard to maintain and can quickly become outdated.
We regard all these limitations as too constraining for a general purpose
memory analysis tool.

Some other studies make use of hardware modification, either actual or
simulated~\cite{Bao08HMTT,Martonosi92MemSpy}.  Although they are eventually able to collect
more precise traces efficiently, they are even less usable than sampling technique: to use
these techniques, one has to have access either to exotic hardware prototypes
(or even build them) or rely on a simulator which might not be realistic
enough.

Binary instrumentation can provide accurate information about memory accesses.
This method is portable and  more precise than the aforementioned ones,
but it comes at the cost of performances. Fast
instrumentations usually either rely on a simulator~\cite{DeRose02SIGMA} which is not as realistic as an actual execution
or collect data at a coarser granularity and gives up temporal
data~\cite{Beniamine15TABARNAC}.


Page fault interception can provide efficient and precise memory traces, it
have been used online for different applications: parallel garbage
collectors~\cite{Boehm91Mostly}, memory
checkpointing~\cite{Heo05Spaceefficient} and NUMA mapping
tools~\cite{Diener13CommunicationBased}. All these tools need to know where a
memory page is and which threads are accessing it, still they only keep a
short history on a small set of pages that they use online. Tracing the state
of the whole memory of an application and storing it efficiently is a
challenge.

In this study we present \Moca, a new \emph{complete} memory trace collection system based on page
fault interception. We compare it to other memory trace tools in term of
performances and collected information details.
